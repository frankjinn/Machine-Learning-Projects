{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loaded spam data!\n",
      "test_data (1000, 32)\n",
      "training_data (4171, 32)\n",
      "training_labels (4171,)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import seaborn\n",
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "\traise Exception(\"Python 3 not detected.\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.stats as stats\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "spamData = np.load(f\"../data/spam-data-hw3.npz\")\n",
    "print(\"\\nloaded %s data!\" % \"spam\")\n",
    "fields = \"test_data\", \"training_data\", \"training_labels\"\n",
    "for field in fields:\n",
    "    print(field, spamData[field].shape)\n",
    "spamTest = spamData[\"test_data\"]\n",
    "spamAllData = spamData[\"training_data\"]\n",
    "spamAllLabels = spamData[\"training_labels\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamTrainX, spamTestX, spamTrainY, spamTestY = train_test_split(spamAllData, spamAllLabels, test_size=500, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam trainData shape:  (3671, 32)\n",
      "spam testData shape:  (500, 32)\n",
      "spam trainLabel shape:  (3671,)\n",
      "spam testLabel shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "print(\"spam trainData shape: \", spamTrainX.shape)\n",
    "print(\"spam testData shape: \", spamTestX.shape)\n",
    "print(\"spam trainLabel shape: \", spamTrainY.shape)\n",
    "print(\"spam testLabel shape: \", spamTestY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMean(inputData, inputLabels):\n",
    "    #Fit Gaussian to Data\n",
    "    spamTrainCount = np.zeros(2)\n",
    "    spamTrainRunningSum = np.zeros((2, 32))\n",
    "    spamTrainMean = np.zeros((2, 32))\n",
    "\n",
    "    for (data, label) in zip(inputData, inputLabels):\n",
    "        spamTrainCount[label] += 1\n",
    "        spamTrainRunningSum[label] += data\n",
    "\n",
    "    for i in range(0,2):\n",
    "        spamTrainMean[i] = spamTrainRunningSum[i] / spamTrainCount[i]\n",
    "    \n",
    "    # print(mnistTrainRunningSum.shape)\n",
    "    # print(mnistTrainMean.shape)\n",
    "    # print(mnistTrainCount[0])\n",
    "\n",
    "    return spamTrainCount, spamTrainMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeClassVarience(inputData, inputLabels, mean):\n",
    "    #QDA Estimation of Varience\n",
    "    classVar = np.zeros((10, 32, 32))\n",
    "\n",
    "    for (data, label) in zip(inputData, inputLabels):\n",
    "        meanDiff = data - mean[label]\n",
    "        classVar[label] += np.outer(meanDiff, meanDiff)\n",
    "    return classVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLDAVar(classVar, totalPoints):\n",
    "    #Find Pooled Varience\n",
    "    pooledVarience = np.zeros((32, 32))\n",
    "    for i in range(0, 2):\n",
    "        pooledVarience += classVar[i]\n",
    "\n",
    "    spamTrainLDAVar = pooledVarience / totalPoints\n",
    "\n",
    "    return spamTrainLDAVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.252\n",
      "0.19799999999999995\n",
      "0.18400000000000005\n",
      "0.17800000000000005\n",
      "0.17400000000000004\n",
      "0.18000000000000005\n"
     ]
    }
   ],
   "source": [
    "def linDiscrim(classIndex, classMean, point, classPreCalc, priorProb):\n",
    "    result = np.dot(classPreCalc[classIndex], point)\n",
    "    result = result - (np.dot(classPreCalc[classIndex], classMean[classIndex]))/2\n",
    "    result = result + np.log(priorProb)\n",
    "    return result\n",
    "\n",
    "errorLin = []\n",
    "for numTestPoints in [100, 200, 500, 1000, 2000, 3671]: \n",
    "    #Train on i points\n",
    "    trainSetX = spamTrainX[:numTestPoints]\n",
    "    trainSetY = spamTrainY[:numTestPoints]\n",
    "\n",
    "    # print(trainSetX.shape)\n",
    "    # print(trainSetY.shape)\n",
    "\n",
    "    classCount, classMean = computeMean(trainSetX, trainSetY)\n",
    "    classVar = computeClassVarience(trainSetX, trainSetY, classMean)\n",
    "    LDAVar = computeLDAVar(classVar, numTestPoints)\n",
    "    LDAVarPseudoInv = np.linalg.pinv(LDAVar)\n",
    "\n",
    "    # print(classMean.shape)\n",
    "    # print(LDAVarPseudoInv.shape)\n",
    "\n",
    "    classPreCalc = {}\n",
    "    #Precalculate some values\n",
    "    for i in range(0, 2):\n",
    "        classPreCalc[i] = np.dot(classMean[i].T, LDAVarPseudoInv)\n",
    "\n",
    "    #Using linear Disc: Test\n",
    "    errorCount = 0\n",
    "    correctCount = 0\n",
    "    for testPointIndex in range(0, len(spamTestX)):\n",
    "        linDisc = np.empty((2))\n",
    "        for i in range(0, 2):\n",
    "            pi = classCount[i]/numTestPoints\n",
    "            #print(pi)\n",
    "            linDisc[i] = linDiscrim(i, classMean, spamTestX[testPointIndex], classPreCalc, pi)\n",
    "        pred = np.argmax(linDisc)\n",
    "        if (pred != spamTestY[testPointIndex]):\n",
    "            errorCount += 1\n",
    "        else:\n",
    "            correctCount += 1\n",
    "    print(1-(correctCount/(errorCount+correctCount)))\n",
    "    errorLin.append((numTestPoints, errorCount/(errorCount+correctCount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numTestPoints in [2000]: \n",
    "    #Train on i points\n",
    "    trainSetX = spamTrainX[:numTestPoints]\n",
    "    trainSetY = spamTrainY[:numTestPoints]\n",
    "\n",
    "    # print(trainSetX.shape)\n",
    "    # print(trainSetY.shape)\n",
    "\n",
    "    classCount, classMean = computeMean(trainSetX, trainSetY)\n",
    "    classVar = computeClassVarience(trainSetX, trainSetY, classMean)\n",
    "    LDAVar = computeLDAVar(classVar, numTestPoints)\n",
    "    LDAVarPseudoInv = np.linalg.pinv(LDAVar)\n",
    "\n",
    "    # print(classMean.shape)\n",
    "    # print(LDAVarPseudoInv.shape)\n",
    "\n",
    "    classPreCalc = {}\n",
    "    #Precalculate some values\n",
    "    for i in range(0, 2):\n",
    "        classPreCalc[i] = np.dot(classMean[i].T, LDAVarPseudoInv)\n",
    "        \n",
    "    pred = []\n",
    "    for testPointIndex in range(0, len(spamTest)):\n",
    "        linDisc = np.empty((2))\n",
    "        for i in range(0, 2):\n",
    "            pi = classCount[i]/numTestPoints\n",
    "            linDisc[i] = linDiscrim(i, classMean, spamTest[testPointIndex], classPreCalc, pi)\n",
    "        pred.append(np.argmax(linDisc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "list = [*range(1, len(pred)+1)]\n",
    "outputDict = {\"Id\":list, \"Category\": pred}\n",
    "df = pd.DataFrame(outputDict)\n",
    "df.to_csv('spamResult.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
